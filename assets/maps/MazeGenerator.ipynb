{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération du Labyrinthe\n",
    "\n",
    "> L'objectif de ce notebook est d'entrainer un modèle à générer des labyrinthes complexes et infinis en utilisant les cartes d'exemple disponibles dans ce même répertoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération du dataset\n",
    "\n",
    "Dans un premier temps, nous cherchons à obtenir un dataset de la forme suivante :\n",
    "$$\n",
    "\\text{Voisinage} \\rightarrow \\text{Case}\n",
    "$$\n",
    "Pour ce faire, nous allons reprendre l'idée des filtres de convolution et balayer le labyrinthe avec un filtre de taille $n\\times n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-> **training_map** : *2 layers*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------- CHARGEMENT DES DONNEES -------------------------- #\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "data = {}\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for filename in sorted(files):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            last_character = filename[-5]\n",
    "            simple_filename = filename.split(\".\")[0]\n",
    "            if simple_filename not in data:\n",
    "                data[simple_filename] = {}\n",
    "            if last_character not in data[simple_filename]:\n",
    "                try:\n",
    "                    csv = pd.read_csv(filename).to_numpy()\n",
    "                except:\n",
    "                    continue\n",
    "                if csv.shape[0] * csv.shape[1] != 0:\n",
    "                    data[simple_filename][last_character] = csv\n",
    "\n",
    "for data_name in data:\n",
    "    display(Markdown(f\"-> **{data_name}** : *{len(data[data_name])} layers*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-> **training_map** : *1 : 42 samples*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-> **training_map** : *2 : 42 samples*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------- CREATON DES DATASETS --------------------------- #\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_datasets(data_list: list, neighbourhood: int = 2):\n",
    "    window_size = neighbourhood * 2 + 1\n",
    "\n",
    "    datasets = {}\n",
    "    for key, data in data_list.items():\n",
    "        # Add padding of size window_size // 2 with -1\n",
    "        data = data.astype(str)\n",
    "        data = np.pad(data, window_size, constant_values=\"border\")\n",
    "        dataset = pd.DataFrame(\n",
    "            [\n",
    "                data[i : i + window_size, j : j + window_size].flatten()\n",
    "                for i in range(0, data.shape[0] - window_size + 1)\n",
    "                for j in range(0, data.shape[1] - window_size + 1)\n",
    "            ]\n",
    "        )\n",
    "        dataset[\"label\"] = dataset[dataset.columns[(window_size**2 - 1) // 2]]\n",
    "        dataset.drop(dataset.columns[(window_size**2 - 1) // 2], axis=1, inplace=True)\n",
    "        dataset = dataset[dataset[\"label\"] != \"border\"]\n",
    "        dataset = dataset.replace(\"border\", -1)\n",
    "        dataset = dataset.astype(int)\n",
    "\n",
    "        datasets[key] = dataset\n",
    "\n",
    "    result_datasets = {}\n",
    "    for key in datasets:\n",
    "        result_datasets[key] = (\n",
    "            pd.concat(\n",
    "                [dataset.drop(columns=[\"label\"]) for dataset in datasets.values()]\n",
    "                + [datasets[key][\"label\"]],\n",
    "                axis=1,\n",
    "            )\n",
    "            .fillna(-1)\n",
    "            .astype(int)\n",
    "        )\n",
    "\n",
    "    return result_datasets\n",
    "\n",
    "\n",
    "datasets = {data_name: create_datasets(data[data_name]) for data_name in data}\n",
    "for dataset in datasets:\n",
    "    for layer in datasets[dataset]:\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"-> **{dataset}** : *{layer} : {len(datasets[dataset][layer])} samples*\"\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets[\"training_map\"][\"1\"].columns))\n",
    "print(len(datasets[\"training_map\"][\"2\"].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ TRAINING MODELS ----------------------------- #\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifiers = {\n",
    "    dataset: {\n",
    "        layer: {\n",
    "            \"model\": RandomForestClassifier(verbose=True, n_jobs=-1).fit(\n",
    "                datasets[dataset][layer].drop(\"label\", axis=1),\n",
    "                datasets[dataset][layer][\"label\"],\n",
    "            ),\n",
    "            \"window_size\": int(\n",
    "                (np.sqrt(datasets[dataset][layer].shape[1] - 1) // 2 + 1)\n",
    "            ),\n",
    "            # List of unique value in the dataframe\n",
    "            \"assets\": dict(\n",
    "                zip(\n",
    "                    *np.unique(\n",
    "                        datasets[dataset][layer].to_numpy().flatten(),\n",
    "                        return_counts=True,\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "        }\n",
    "        for layer in datasets[dataset]\n",
    "    }\n",
    "    for dataset in datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ GENERATING MAZE ----------------------------- #\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_maze(classifiers: dict, size: tuple, nbr_iter=5, temperature=0.1):\n",
    "    mazes = {}\n",
    "\n",
    "    # Unpack Arguments\n",
    "    size_x, size_y = size\n",
    "    window_size = classifiers[list(classifiers.keys())[0]][\"window_size\"]\n",
    "    assets_list = {key: classifier[\"assets\"] for key, classifier in classifiers.items()}\n",
    "    models = {key: classifier[\"model\"] for key, classifier in classifiers.items()}\n",
    "\n",
    "    # Generate Maze\n",
    "    ## Generate a matrix full of random values from the assets\n",
    "    mazes = {\n",
    "        key: np.random.choice(\n",
    "            list(assets.keys()),\n",
    "            (size_x, size_y),\n",
    "            p=list(assets.values()) / np.sum(list(assets.values())),\n",
    "        )\n",
    "        for key, assets in assets_list.items()\n",
    "    }\n",
    "\n",
    "    # Apply the classifier on the maze\n",
    "    for _ in range(nbr_iter):\n",
    "        # Generate dataset from the maze\n",
    "        datasets = create_datasets(mazes, window_size // 2)\n",
    "\n",
    "        for key, model in models.items():\n",
    "            # Apply the classifier on the dataset\n",
    "            logits = model.predict_proba(datasets[key].drop(\"label\", axis=1))\n",
    "            logits = logits ** (1 / temperature)\n",
    "            predictions = np.array(\n",
    "                [\n",
    "                    np.random.choice(model.classes_, p=logit / logit.sum())\n",
    "                    for logit in logits\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Recreate the maze from the predictions\n",
    "            mazes[key] = np.array(predictions).reshape(size_x, size_y)\n",
    "\n",
    "    return mazes\n",
    "\n",
    "\n",
    "mazes = generate_maze(classifiers[\"training_map\"], (25, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------- PLOT MAP --------------------------------- #\n",
    "import os\n",
    "import pygame\n",
    "import itertools\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "def plot_map(mazes: dict):\n",
    "    width, height = mazes[list(mazes.keys())[0]].shape\n",
    "\n",
    "    assets = {}\n",
    "    for root, dirs, files in os.walk(os.path.join(\"..\", \"frames\")):\n",
    "        # Remove files starting with a capital letter\n",
    "        files = [f for f in files if not f[0].isupper()]\n",
    "        for i, filename in enumerate(sorted(files)):\n",
    "            if i in list(\n",
    "                itertools.chain.from_iterable(\n",
    "                    [maze.flatten().tolist() for maze in mazes.values()]\n",
    "                )\n",
    "            ):\n",
    "                assets[i] = pygame.image.load(os.path.join(root, filename))\n",
    "    # Create a black image for -1 (16x16) with alpha channel\n",
    "    assets[-1] = pygame.Surface((16, 16), pygame.SRCALPHA)\n",
    "\n",
    "    # Create window\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((width * 16, height * 16))\n",
    "    pygame.display.set_caption(\"Maze\")\n",
    "    screen.fill((0, 0, 0))\n",
    "\n",
    "    # Draw the mazes\n",
    "    for maze in mazes.values():\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                screen.blit(assets[maze[i, j]], (i * 16, j * 16), special_flags=0)\n",
    "\n",
    "    pygame.display.flip()\n",
    "    pygame.image.save(screen, \"maze.png\")\n",
    "    pygame.quit()\n",
    "\n",
    "    # Display the maze\n",
    "    display(Image(filename=\"maze.png\"))\n",
    "\n",
    "\n",
    "plot_map(mazes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
